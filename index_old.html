<!doctype html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport"
        content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <title>Hello WebXR!</title>

    <!-- three.js -->
    <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>

<body>

    <!-- Starting an immersive WebXR session requires user interaction.
    We start this one with a simple button. -->
    <button onclick="activateXR()">Start Hello WebXR</button>
    <script>
        async function activateXR() {
            // Add a canvas element and initialize a WebGL context that is compatible with WebXR.
            const canvas = document.createElement("canvas");
            document.body.appendChild(canvas);
            const gl = canvas.getContext("webgl", { xrCompatible: true });

            // To be continued in upcoming steps.
            const scene = new THREE.Scene();

            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
            directionalLight.position.set(10, 15, 10);
            scene.add(directionalLight);

            // Set up the WebGLRenderer, which handles rendering to the session's base layer.
            const renderer = new THREE.WebGLRenderer({
                alpha: true,
                preserveDrawingBuffer: true,
                canvas: canvas,
                context: gl
            });
            renderer.autoClear = false;

            // The API directly updates the camera matrices.
            // Disable matrix auto updates so three.js doesn't attempt
            // to handle the matrices independently.
            const camera = new THREE.PerspectiveCamera();
            camera.matrixAutoUpdate = false;

            // Initialize a WebXR session using "immersive-ar".
            const session = await navigator.xr.requestSession("immersive-ar", {
                requiredFeatures: ["depth-sensing"],
                depthSensing: {
                    usagePreference: ["cpu-optimized", "gpu-optimized"],
                    dataFormatPreference: ["luminance-alpha", "float32"]
                }
            });

            console.log(session.depthUsage);
            console.log(session.depthFormat);

            session.updateRenderState({
                baseLayer: new XRWebGLLayer(session, gl)
            });

            // A 'local' reference space has a native origin that is located
            // near the viewer's position at the time the session was created.
            const referenceSpace = await session.requestReferenceSpace('local');

            // Create another XRReferenceSpace that has the viewer as the origin.
            const viewerSpace = await session.requestReferenceSpace('viewer');
            // Perform hit testing using the viewer as origin.
            const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

            const loader = new THREE.GLTFLoader();
            let reticle;
            loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function (gltf) {
                reticle = gltf.scene;
                reticle.visible = false;
                scene.add(reticle);
            })

            let flower;
            loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf", function (gltf) {
                flower = gltf.scene;
            });

            session.addEventListener("select", (event) => {
                if (flower) {
                    const clone = flower.clone();
                    clone.position.copy(reticle.position);
                    scene.add(clone);
                }
            });

            const polygonize = (view, backgroundLayer) => {

                const viewport = backgroundLayer.getViewport(view);

                const mininumDistance = 0.05;

                const faceDistanceTreshold = 1.4 * mininumDistance;

                const pairIntegers = (a, b) => {
                    return Math.round(((a + b) * (a + b + 1) + b) / 2);
                }

                const tripletIntegers = (a, b, c) => {
                    return pairIntegers(pairIntegers(a, b), c);
                }

                const isTooClose = (pos, minDist, arr) => {
                    for (var i = 0; i < arr.length; i++) {
                        if (pos.distanceTo(arr[i]) < minDist) return true;
                    }
                    return false;
                }

                const viewMatInv = new THREE.Matrix4().fromArray(view.projectionMatrix).invert();
                const camMatrix = new THREE.Matrix4().fromArray(view.transform.matrix);
                const camPosition = new THREE.Vector3().setFromMatrixPosition(camMatrix);
                const depthInfo = frame.getDepthInformation(view);

                const vertices = [];
                const uvs = [];
                const faces = [];

                if (depthInfo == null) {
                    // Handle the case where current frame does not carry depth information.
                }
                else {
                    for (var x = 0; x < depthInfo.width; x++) {
                        for (var y = 0; y < depthInfo.height; y++) {
                            const position = new THREE.Vector3(2 * x / depthInfo.width - 1, 2 * y / depthInfo.height - 1, 0.5)
                                .applyMatrix4(viewMatInv)
                                .applyMatrix4(camMatrix)
                                .sub(camPosition)
                                .normalized()
                                .multiplyScalar(depthInfo.getDepthInMeters(x, y));
                            if (!isTooClose(position, mininumDistance, vertices)) {
                                uvs.push(x / depthInfo.width, y / depthInfo.height);
                                vertices.push(position);
                            }
                        }
                    }
                    const triplets = [];
                    for (var i = 0; i + 2 < vertices.length; i++) {
                        for (var j = i + 1; j + 1 < vertices.length; j++) {
                            if (vertices[i].distanceTo(vertices[j]) < faceDistanceTreshold) {
                                for (var k = j + 1; k < vertices.length; k++) {
                                    if (triplets.indexOf(tripletIntegers(i, j, k)) != -1 && vertices[k].distanceTo(vertices[i]) < faceDistanceTreshold && vertices[k].distanceTo(vertices[j]) < faceDistanceTreshold) {
                                        faces.push(i, j, k);
                                        triplets.push(tripletIntegers(i, j, k));
                                    }
                                }
                            }
                        }
                    }
                    if (triplets.length > 0) {
                        const vertexData = [];
                        var vertexValuesIndex = 0;
                        for (var i = 0; i < vertices.length; i++) {
                            vertexData[vertexValuesIndex++] = vertices[i].x;
                            vertexData[vertexValuesIndex++] = vertices[i].y;
                            vertexData[vertexValuesIndex++] = vertices[i].z;
                        }

                        const genGeometry = new THREE.BufferGeometry();
                        genGeometry.setIndex(triplets);
                        genGeometry.setAttribute('position', new THREE.BufferAttribute(new Float32Array(vertexData), 3, false));
                        genGeometry.setAttribute('uv', new THREE.BufferAttribute(new Float32Array(uvs), 2, true));

                        genGeometry.computeVertexNormals();


                        const genMaterial = new THREE.MeshPhongMaterial({
                            side: THREE.DoubleSide,
                        });
                        var xrTexture = new THREE.FrameBufferTexture(viewport.width, viewport.height, THREE.RGBAFormat);
                        //assumes xr framebuffer is bound to gl context
                        renderer.copyFramebufferToTexture(new THREE.Vector2(0, 0), xrTexture, 0);

                        genMaterial.map = xrTexture;
                        const genMesh = new THREE.Mesh(genGeometry, genMaterial);
                        scene.add(genMesh);
                    }
                }

            }

            const onXRFrame = (time, frame) => {
                // Queue up the next draw request.
                session.requestAnimationFrame(onXRFrame);

                // Bind the graphics framebuffer to the baseLayer's framebuffer
                gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

                // Retrieve the pose of the device.
                // XRFrame.getViewerPose can return null while the session attempts to establish tracking.
                const pose = frame.getViewerPose(referenceSpace);
                if (pose) {
                    // In mobile AR, we only have one view.
                    const view = pose.views[0];

                    polygonize(view);

                    const viewport = session.renderState.baseLayer.getViewport(view);
                    renderer.setSize(viewport.width, viewport.height)

                    // Use the view's transform matrix and projection matrix to configure the THREE.camera.
                    camera.matrix.fromArray(view.transform.matrix)
                    camera.projectionMatrix.fromArray(view.projectionMatrix);
                    camera.updateMatrixWorld(true);

                    const hitTestResults = frame.getHitTestResults(hitTestSource);
                    if (hitTestResults.length > 0 && reticle) {
                        const hitPose = hitTestResults[0].getPose(referenceSpace);
                        reticle.visible = true;
                        reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z)
                        reticle.updateMatrixWorld(true);
                    }

                    // Render the scene with THREE.WebGLRenderer.
                    renderer.render(scene, camera)
                }
            }
            session.requestAnimationFrame(onXRFrame);
        }

    </script>
</body>

</html>